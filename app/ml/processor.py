import logging
from io import BytesIO
import torch
from transformers import AutoProcessor, AutoModelForImageClassification
from PIL import Image
import numpy as np
import cv2
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)

# ØªÙØ¹ÙŠÙ„ ÙˆØ¶Ø¹ GPU Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
logger.info(f'ðŸ–¥ï¸  Ø¬Ù‡Ø§Ø² Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {DEVICE}')


class MLProcessor:
    """Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ù„ØªØ­Ù„ÙŠÙ„ ØµÙˆØ± Ø§Ù„Ø£Ø´Ø¹Ø© Ø§Ù„Ø³ÙŠÙ†ÙŠØ©."""
    
    def __init__(self):
        self.processor = None
        self.model = None
        self.LABELS = ["NORMAL", "PNEUMONIA"]
        self.EXPLANATIONS = {
            'NORMAL': {
                'ar': 'Ø§Ù„ØµÙˆØ±Ø© Ø·Ø¨ÙŠØ¹ÙŠØ©. Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¯Ù„ÙŠÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ‡Ø§Ø¨ Ø±Ø¦ÙˆÙŠ.',
                'en': 'The image is normal. No evidence of pneumonia.'
            },
            'PNEUMONIA': {
                'ar': 'ØªÙ… Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„ØªÙ‡Ø§Ø¨ Ø±Ø¦ÙˆÙŠ. ÙŠÙØ±Ø¬Ù‰ Ø§Ø³ØªØ´Ø§Ø±Ø© Ø§Ù„Ø·Ø¨ÙŠØ¨ Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©.',
                'en': 'Pneumonia detected. Please consult a doctor for review.'
            }
        }
        self.is_loaded = False

    def load_model(self, model_repo: str, hf_token: Optional[str] = None):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ ÙˆØ§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ†Ù‚Ù„Ù‡ Ø¥Ù„Ù‰ ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©."""
        try:
            logger.info(f'ðŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù†: {model_repo}')
            logger.info(f'ðŸ“± Ø¬Ù‡Ø§Ø² Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {DEVICE}')
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ ÙˆØ§Ù„Ù†Ù…ÙˆØ°Ø¬
            self.processor = AutoProcessor.from_pretrained(model_repo, token=hf_token)
            self.model = AutoModelForImageClassification.from_pretrained(model_repo, token=hf_token)
            
            # Ù†Ù‚Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ù…Ø­Ø¯Ø¯
            self.model.to(DEVICE)
            self.model.eval()
            
            # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªØ±ØªÙŠØ¨ Ø§Ù„ØªØ³Ù…ÙŠØ§Øª
            if self.model.config.id2label:
                self.LABELS = [self.model.config.id2label.get(i) for i in range(len(self.model.config.id2label))]
            
            self.is_loaded = True
            logger.info(f'âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­ Ø¹Ù„Ù‰ {DEVICE}')
            logger.info(f'ðŸ“Š Ø§Ù„ØªØ³Ù…ÙŠØ§Øª: {self.LABELS}')
            
        except Exception as e:
            logger.error(f'âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}', exc_info=True)
            self.model = None
            self.is_loaded = False
            raise

    def _preprocess_image(self, image_bytes: bytes) -> Image.Image:
        """
        Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©.
        
        Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª:
            image_bytes: Ø¨Ø§ÙŠØªØ§Øª Ø§Ù„ØµÙˆØ±Ø©
        
        Ø§Ù„Ø¥Ø±Ø¬Ø§Ø¹:
            PIL.Image: Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
        """
        if not isinstance(image_bytes, bytes):
            raise ValueError('image_bytes must be bytes')
        
        if len(image_bytes) == 0:
            raise ValueError('image_bytes is empty')
            
        image = Image.open(BytesIO(image_bytes)).convert('RGB')
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø©
        if image.size[0] < 50 or image.size[1] < 50:
            raise ValueError('Ø§Ù„ØµÙˆØ±Ø© ØµØºÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹')
            
        return image

    @torch.no_grad()
    def analyze_image(self, image_bytes: bytes) -> Dict[str, Any]:
        """
        Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„ØµÙˆØ±Ø©.
        
        Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª:
            image_bytes: Ø¨Ø§ÙŠØªØ§Øª Ø§Ù„ØµÙˆØ±Ø©
        
        Ø§Ù„Ø¥Ø±Ø¬Ø§Ø¹:
            dict: Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙˆØ§Ù„Ø«Ù‚Ø© ÙˆØ§Ù„Ø´Ø±Ø­
        """
        if self.model is None:
            raise RuntimeError('Model is not loaded or available.')
        
        try:
            # 1. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©)
            image = self._preprocess_image(image_bytes)
            
            # 2. Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            inputs = self.processor(images=image, return_tensors="pt").to(DEVICE)
            
            # 3. Ø§Ù„ØªÙ†Ø¨Ø¤
            outputs = self.model(**inputs)
            logits = outputs.logits
            
            # 4. Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© ÙˆØ§Ù„Ù†ØªÙŠØ¬Ø©
            probabilities = torch.softmax(logits, dim=1)[0]
            confidence, predicted_index = torch.max(probabilities, 0)
            
            label = self.LABELS[predicted_index.item()]
            confidence_percent = round(confidence.item() * 100, 2)
            
            logger.info(f'âœ… ØªØ­Ù„ÙŠÙ„ Ù†Ø§Ø¬Ø­: {label} ({confidence_percent}%)')
            
            return {
                'result': label,
                'confidence': confidence_percent,
                'explanation': self.EXPLANATIONS.get(label, self.EXPLANATIONS['NORMAL']),
                'probabilities': {
                    'NORMAL': round(probabilities[0].item() * 100, 2),
                    'PNEUMONIA': round(probabilities[1].item() * 100, 2)
                }
            }
            
        except Exception as e:
            logger.error(f'Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©: {str(e)}', exc_info=True)
            raise
        finally:
            # --- ØªØ­Ø³ÙŠÙ†: ØªÙ†Ø¸ÙŠÙ Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù€ GPU ---
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

    def compute_saliency_map(self, image_bytes: bytes) -> Optional[Image.Image]:
        """
        Ø­Ø³Ø§Ø¨ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø¥Ø¨Ø±Ø§Ø² (Saliency Map) Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ‚Ù†ÙŠØ© Gradient.
        
        Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª:
            image_bytes: Ø¨Ø§ÙŠØªØ§Øª Ø§Ù„ØµÙˆØ±Ø© (ØªÙ… ØªØºÙŠÙŠØ±Ù‡ Ù…Ù† image_pil)
        
        Ø§Ù„Ø¥Ø±Ø¬Ø§Ø¹:
            PIL.Image: Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø¥Ø¨Ø±Ø§Ø²
        """
        if self.model is None:
            logger.warning('Ù„Ù… ÙŠØªÙ… Ø­Ø³Ø§Ø¨ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø¥Ø¨Ø±Ø§Ø²: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø­Ù…Ù„')
            return None
        
        try:
            # --- ØªØ­Ø³ÙŠÙ†: Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† Ø§Ù„Ø¨Ø§ÙŠØªØ§Øª ---
            image = self._preprocess_image(image_bytes)
            
            # 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
            inputs = self.processor(images=image, return_tensors="pt").to(DEVICE)
            # Ù†Ø­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¯Ø±Ø¬Ø§ØªØŒ Ù„Ø°Ø§ Ù†ÙØ¹Ù‘Ù„Ù‡Ø§
            inputs['pixel_values'].requires_grad_(True)
            
            # 2. Ø­Ø³Ø§Ø¨ Ø§Ù„Ù€ Gradient
            self.model.zero_grad()
            outputs = self.model(**inputs)
            predicted_index = outputs.logits.argmax(dim=1)
            target_score = outputs.logits[0, predicted_index]
            target_score.backward(retain_graph=True) # retain_graph=True Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø¶Ø±ÙˆØ±ÙŠØ§Ù‹ ÙÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ø­Ø§Ù„Ø§Øª
            
            # 3. Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª
            gradients = inputs['pixel_values'].grad.abs().squeeze(0).cpu().numpy()
            saliency = np.sum(gradients, axis=0)
            
            # 4. ØªØ³ÙˆÙŠØ© Ø§Ù„Ø®Ø±ÙŠØ·Ø©
            saliency_min = saliency.min()
            saliency_max = saliency.max()
            
            if saliency_max - saliency_min == 0:
                saliency_map = np.zeros_like(saliency)
            else:
                saliency_map = (saliency - saliency_min) / (saliency_max - saliency_min)
            
            # 5. ØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Ø®Ø±ÙŠØ·Ø© Ø­Ø±Ø§Ø±Ø©
            saliency_map = (saliency_map * 255).astype(np.uint8)
            saliency_map_resized = cv2.resize(saliency_map, image.size)
            heatmap = cv2.applyColorMap(saliency_map_resized, cv2.COLORMAP_JET)
            
            # 6. Ø¯Ù…Ø¬ Ù…Ø¹ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
            image_cv = np.array(image)
            # OpenCV uses BGR, so we convert the PIL image (RGB) to BGR
            image_cv_bgr = cv2.cvtColor(image_cv, cv2.COLOR_RGB2BGR)
            
            alpha = 0.5
            overlay = cv2.addWeighted(image_cv_bgr, 1 - alpha, heatmap, alpha, 0)
            
            # 7. ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¥Ù„Ù‰ PIL
            overlay_pil = Image.fromarray(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))
            
            logger.info('âœ… ØªÙ… Ø­Ø³Ø§Ø¨ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø¥Ø¨Ø±Ø§Ø² Ø¨Ù†Ø¬Ø§Ø­')
            return overlay_pil
            
        except Exception as e:
            logger.error(f'Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø¥Ø¨Ø±Ø§Ø²: {str(e)}', exc_info=True)
            return None
        finally:
            # --- ØªØ­Ø³ÙŠÙ†: ØªÙ†Ø¸ÙŠÙ Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù€ GPU ---
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
    
    def get_model_info(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬."""
        if not self.is_loaded:
            return {'error': 'Model not loaded'}
        
        return {
            'labels': self.LABELS,
            'device': str(DEVICE),
            'is_loaded': self.is_loaded,
            'model_config': {
                'num_labels': self.model.config.num_labels if hasattr(self.model.config, 'num_labels') else None
            }
        }