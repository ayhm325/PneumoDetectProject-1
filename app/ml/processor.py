import logging
from io import BytesIO
import torch
from transformers import AutoProcessor, AutoModelForImageClassification
from PIL import Image
import numpy as np
import cv2

logger = logging.getLogger(__name__)

# ØªÙØ¹ÙŠÙ„ ÙˆØ¶Ø¹ GPU Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
logger.info(f'ğŸ–¥ï¸  Ø¬Ù‡Ø§Ø² Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {DEVICE}')


class MLProcessor:
    """Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ù„ØªØ­Ù„ÙŠÙ„ ØµÙˆØ± Ø§Ù„Ø£Ø´Ø¹Ø© Ø§Ù„Ø³ÙŠÙ†ÙŠØ©."""
    
    def __init__(self):
        self.processor = None
        self.model = None
        self.LABELS = ["NORMAL", "PNEUMONIA"]
        self.EXPLANATIONS = {
            'NORMAL': {
                'ar': 'Ø§Ù„ØµÙˆØ±Ø© Ø·Ø¨ÙŠØ¹ÙŠØ©. Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¯Ù„ÙŠÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ‡Ø§Ø¨ Ø±Ø¦ÙˆÙŠ.',
                'en': 'The image is normal. No evidence of pneumonia.'
            },
            'PNEUMONIA': {
                'ar': 'ØªÙ… Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„ØªÙ‡Ø§Ø¨ Ø±Ø¦ÙˆÙŠ. ÙŠÙØ±Ø¬Ù‰ Ø§Ø³ØªØ´Ø§Ø±Ø© Ø§Ù„Ø·Ø¨ÙŠØ¨ Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©.',
                'en': 'Pneumonia detected. Please consult a doctor for review.'
            }
        }
        self.is_loaded = False

    def load_model(self, model_repo, hf_token=None):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ ÙˆØ§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ†Ù‚Ù„Ù‡ Ø¥Ù„Ù‰ ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©."""
        try:
            logger.info(f'ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù†: {model_repo}')
            logger.info(f'ğŸ“± Ø¬Ù‡Ø§Ø² Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {DEVICE}')
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ ÙˆØ§Ù„Ù†Ù…ÙˆØ°Ø¬
            self.processor = AutoProcessor.from_pretrained(model_repo, token=hf_token)
            self.model = AutoModelForImageClassification.from_pretrained(model_repo, token=hf_token)
            
            # Ù†Ù‚Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ù…Ø­Ø¯Ø¯
            self.model.to(DEVICE)
            self.model.eval()
            
            # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªØ±ØªÙŠØ¨ Ø§Ù„ØªØ³Ù…ÙŠØ§Øª
            if self.model.config.id2label:
                self.LABELS = [self.model.config.id2label.get(i) for i in range(len(self.model.config.id2label))]
            
            self.is_loaded = True
            logger.info(f'âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­ Ø¹Ù„Ù‰ {DEVICE}')
            logger.info(f'ğŸ“Š Ø§Ù„ØªØ³Ù…ÙŠØ§Øª: {self.LABELS}')
            
        except Exception as e:
            logger.error(f'âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}', exc_info=True)
            self.model = None
            self.is_loaded = False
            raise

    @torch.no_grad()
    def analyze_image(self, image_bytes):
        """
        Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„ØµÙˆØ±Ø©.
        
        Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª:
            image_bytes: Ø¨Ø§ÙŠØªØ§Øª Ø§Ù„ØµÙˆØ±Ø©
        
        Ø§Ù„Ø¥Ø±Ø¬Ø§Ø¹:
            dict: Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙˆØ§Ù„Ø«Ù‚Ø© ÙˆØ§Ù„Ø´Ø±Ø­ ÙˆØ§Ù„ØµÙˆØ±Ø©
        """
        if self.model is None:
            raise Exception('Model is not loaded or available.')
        
        if not isinstance(image_bytes, bytes):
            raise ValueError('image_bytes must be bytes')
        
        if len(image_bytes) == 0:
            raise ValueError('image_bytes is empty')
        
        try:
            # 1. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©
            image = Image.open(BytesIO(image_bytes)).convert('RGB')
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø©
            if image.size[0] < 50 or image.size[1] < 50:
                raise ValueError('Ø§Ù„ØµÙˆØ±Ø© ØµØºÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹')
            
            # 2. Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            inputs = self.processor(images=image, return_tensors="pt").to(DEVICE)
            
            # 3. Ø§Ù„ØªÙ†Ø¨Ø¤
            outputs = self.model(**inputs)
            logits = outputs.logits
            
            # 4. Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© ÙˆØ§Ù„Ù†ØªÙŠØ¬Ø©
            probabilities = torch.softmax(logits, dim=1)[0]
            confidence, predicted_index = torch.max(probabilities, 0)
            
            label = self.LABELS[predicted_index.item()]
            confidence_percent = round(confidence.item() * 100, 2)
            
            logger.info(f'âœ… ØªØ­Ù„ÙŠÙ„ Ù†Ø§Ø¬Ø­: {label} ({confidence_percent}%)')
            
            return {
                'result': label,
                'confidence': confidence_percent,
                'explanation': self.EXPLANATIONS.get(label, self.EXPLANATIONS['NORMAL']),
                'image_pil': image,
                'probabilities': {
                    'NORMAL': round(probabilities[0].item() * 100, 2),
                    'PNEUMONIA': round(probabilities[1].item() * 100, 2)
                }
            }
            
        except Exception as e:
            logger.error(f'Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©: {str(e)}', exc_info=True)
            raise

    def compute_saliency_map(self, image_pil):
        """
        Ø­Ø³Ø§Ø¨ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø¥Ø¨Ø±Ø§Ø² (Saliency Map) Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ‚Ù†ÙŠØ© Gradient.
        
        Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª:
            image_pil: ØµÙˆØ±Ø© PIL
        
        Ø§Ù„Ø¥Ø±Ø¬Ø§Ø¹:
            PIL.Image: Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø¥Ø¨Ø±Ø§Ø²
        """
        if self.model is None or not image_pil:
            logger.warning('Ù„Ù… ÙŠØªÙ… Ø­Ø³Ø§Ø¨ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø¥Ø¨Ø±Ø§Ø²: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø­Ù…Ù„')
            return None
        
        try:
            # 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
            image = image_pil.copy()
            inputs = self.processor(images=image, return_tensors="pt").to(DEVICE)
            inputs['pixel_values'].requires_grad_(True)
            
            # 2. Ø­Ø³Ø§Ø¨ Ø§Ù„Ù€ Gradient
            self.model.zero_grad()
            outputs = self.model(**inputs)
            predicted_index = outputs.logits.argmax(dim=1)
            target_score = outputs.logits[0, predicted_index]
            target_score.backward()
            
            # 3. Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª
            gradients = inputs['pixel_values'].grad.abs().squeeze(0).cpu().numpy()
            saliency = np.sum(gradients, axis=0)
            
            # 4. ØªØ³ÙˆÙŠØ© Ø§Ù„Ø®Ø±ÙŠØ·Ø©
            saliency_min = saliency.min()
            saliency_max = saliency.max()
            
            if saliency_max - saliency_min == 0:
                saliency_map = np.zeros_like(saliency)
            else:
                saliency_map = (saliency - saliency_min) / (saliency_max - saliency_min)
            
            # 5. ØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Ø®Ø±ÙŠØ·Ø© Ø­Ø±Ø§Ø±Ø©
            saliency_map = (saliency_map * 255).astype(np.uint8)
            saliency_map_resized = cv2.resize(saliency_map, image_pil.size)
            heatmap = cv2.applyColorMap(saliency_map_resized, cv2.COLORMAP_JET)
            
            # 6. Ø¯Ù…Ø¬ Ù…Ø¹ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
            image_cv = np.array(image_pil.convert('RGB'))
            image_cv = cv2.cvtColor(image_cv, cv2.COLOR_RGB2BGR)
            
            alpha = 0.5
            overlay = cv2.addWeighted(image_cv, 1 - alpha, heatmap, alpha, 0)
            
            # 7. ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¥Ù„Ù‰ PIL
            overlay_pil = Image.fromarray(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))
            
            logger.info('âœ… ØªÙ… Ø­Ø³Ø§Ø¨ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø¥Ø¨Ø±Ø§Ø² Ø¨Ù†Ø¬Ø§Ø­')
            return overlay_pil
            
        except Exception as e:
            logger.error(f'Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø¥Ø¨Ø±Ø§Ø²: {str(e)}', exc_info=True)
            return None
    
    def get_model_info(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬."""
        if not self.is_loaded:
            return {'error': 'Model not loaded'}
        
        return {
            'labels': self.LABELS,
            'device': str(DEVICE),
            'is_loaded': self.is_loaded,
            'model_config': {
                'num_labels': self.model.config.num_labels if hasattr(self.model.config, 'num_labels') else None
            }
        }